# api.py
import logging
import time
import uuid
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware

# Imports da Aplica√ß√£o
from app.services.orchestrator import Orchestrator
from app.api import dashboard
# IMPORTANTE: Importamos os modelos do schemas.py em vez de redefinir
from app.core.schemas import ChatRequest, ChatResponse

# Configura√ß√£o de Logs
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)

# Inicializa√ß√£o da App
app = FastAPI(
    title="Supporte BI AI - Enterprise Backend",
    description="API Orquestrada com Arquitetura Hub-and-Spoke",
    version="2.2"
)

# Configura CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Rotas de Dashboard (KPIs r√°pidos)
app.include_router(dashboard.router, prefix="/api/dashboard")

# --- Endpoint de Chat ---

@app.post("/chat", response_model=ChatResponse)
async def chat_endpoint(request: ChatRequest):
    """
    Endpoint principal.
    Recebe a pergunta -> Passa para o Orchestrator -> Retorna resposta estruturada e validada.
    """
    start_time = time.time()
    
    # 1. Gest√£o de Sess√£o
    session_id = request.session_id or str(uuid.uuid4())
    logger.info(f"üì® [API] Nova requisi√ß√£o | Sess√£o: {session_id[:8]} | Pergunta: '{request.question}'")

    try:
        # 2. Execu√ß√£o da Pipeline
        result = Orchestrator.run_pipeline(
            session_id=session_id,
            question=request.question
        )

        # 3. Formata√ß√£o Final
        total_duration = time.time() - start_time
        
        # Montamos um dicion√°rio que o Pydantic (ChatResponse) ir√° validar e serializar
        response_data = {
            "type": result.get("type", "text"),
            "content": result.get("content", ""),
            "session_id": session_id,
            "query": request.question,
            "response_time": f"{total_duration:.2f}",
            "server_execution_time": result.get("execution_time", 0),
            
            # Campos opcionais (DataResponse)
            "sql": result.get("sql"),
            "data": result.get("data"),
            "chart_suggestion": result.get("chart_suggestion")
        }

        logger.info(f"‚úÖ [API] Resposta enviada em {total_duration:.2f}s (Tipo: {response_data['type']})")
        return response_data

    except Exception as e:
        logger.critical(f"üî• [API CRITICAL ERROR] {e}", exc_info=True)
        # Fallback de erro compat√≠vel com ErrorResponse
        return {
            "type": "error",
            "content": "Ocorreu um erro interno cr√≠tico no servidor.",
            "session_id": session_id,
            "query": request.question,
            "response_time": f"{time.time() - start_time:.2f}",
            "server_execution_time": 0.0,
            "debug_info": str(e) # Em produ√ß√£o, pode remover isso para seguran√ßa
        }

@app.get("/")
def read_root():
    return {"status": "online", "system": "Supporte BI Enterprise v2.2", "security_guard": "active"}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8002)