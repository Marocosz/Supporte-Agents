# api.py
import logging
import time
import uuid
from typing import List, Dict, Any, Optional
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

# Importa o C√©rebro da Nova Arquitetura
from app.services.orchestrator import Orchestrator
# Importa o m√≥dulo de dashboard (KPIs est√°ticos) - Mantido para n√£o quebrar a tela de gr√°ficos
from app.api import dashboard

# Configura√ß√£o de Logs
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)

# Inicializa√ß√£o da App
app = FastAPI(
    title="Supporte BI AI - Enterprise Backend",
    description="API Orquestrada com Arquitetura Hub-and-Spoke (Router -> Specialists)",
    version="2.1"
)

# Configura CORS (Permite que o Frontend React acesse)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], # Em produ√ß√£o, restrinja para o dom√≠nio do front
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Rotas de Dashboard (KPIs r√°pidos que n√£o dependem da IA)
app.include_router(dashboard.router, prefix="/api/dashboard")

# --- Modelos de Entrada (DTOs) ---

class ChatRequest(BaseModel):
    question: str
    session_id: str | None = None
    # Hist√≥rico opcional (O Orchestrator gerencia contexto internamente agora, 
    # mas mantemos o campo para compatibilidade)
    history: List[Dict[str, str]] = [] 

# --- Endpoint de Chat (O Cora√ß√£o do Sistema) ---

@app.post("/chat")
async def chat_endpoint(request: ChatRequest):
    """
    Endpoint principal.
    Recebe a pergunta -> Passa para o Orchestrator -> Retorna resposta estruturada.
    """
    start_time = time.time()
    
    # 1. Gest√£o de Sess√£o
    session_id = request.session_id or str(uuid.uuid4())
    logger.info(f"üì® [API] Nova requisi√ß√£o | Sess√£o: {session_id[:8]} | Pergunta: '{request.question}'")

    try:
        # 2. Execu√ß√£o da Pipeline (Onde a m√°gica acontece)
        # O Orchestrator cuida de tudo: Routing, SQL, Seguran√ßa, RAG.
        result = Orchestrator.run_pipeline(
            session_id=session_id,
            question=request.question
        )

        # 3. Formata√ß√£o Final para o Frontend
        # Garantimos que os campos t√©cnicos estejam presentes para debug
        total_duration = time.time() - start_time
        
        response = {
            "type": result.get("type", "text"),
            "content": result.get("content", ""),
            "session_id": session_id,
            "query": request.question,
            # Metadados t√©cnicos
            "sql": result.get("sql"),          # S√≥ existe se for Tracking/Analytics
            "data": result.get("data"),        # Dados brutos para gr√°ficos
            "category": result.get("category"), # TRACKING, ANALYTICS, etc.
            "response_time": f"{total_duration:.2f}",
            "server_execution_time": result.get("execution_time", 0)
        }

        logger.info(f"‚úÖ [API] Resposta enviada em {total_duration:.2f}s (Tipo: {response['type']})")
        return response

    except Exception as e:
        logger.critical(f"üî• [API CRITICAL ERROR] {e}", exc_info=True)
        # Fallback seguro: Nunca deixe o frontend sem resposta
        return {
            "type": "error",
            "content": "Ocorreu um erro interno cr√≠tico no servidor. Por favor, tente novamente em instantes.",
            "session_id": session_id,
            "response_time": f"{time.time() - start_time:.2f}"
        }

@app.get("/")
def read_root():
    return {"status": "online", "system": "Supporte BI Enterprise v2.1", "security_guard": "active"}

# Permite rodar como script: python api.py
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8002)